{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iT-T2AV2D03S"
      },
      "source": [
        "# 0) Import and install libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qYaPtjroDqyr",
        "outputId": "dad5069f-ed52-4e35-ad9a-df9c9e01f116"
      },
      "outputs": [],
      "source": [
        "use_google_colab = True\n",
        "if use_google_colab:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/gdrive')\n",
        "    %cd \"/gdrive/MyDrive/Colab Notebooks/Scientific Computing Tools for Advanced Mathematical Modeling/FinalProject\"\n",
        "    !pip install tqdm\n",
        "    !pip install FDApy\n",
        "    import FDApy\n",
        "    from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "    from FDApy.preprocessing.dim_reduction.fpca import UFPCA\n",
        "    from FDApy.visualization.plot import plot\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "from scipy.stats import multivariate_normal\n",
        "from sklearn.cluster import KMeans\n",
        "from time import time\n",
        "from sklearn.metrics.pairwise import euclidean_distances\n",
        "from sys import getsizeof\n",
        "\n",
        "from logger import logger, TeseoLogger\n",
        "\n",
        "# Random seed for reproducibility\n",
        "seed = 427\n",
        "\n",
        "random.seed(seed)\n",
        "os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "np.random.seed(seed)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BW6JdoXmGVoz"
      },
      "source": [
        "# 1) Load the dataset:\n",
        "\n",
        "The dataset is composed of:\n",
        "*   coordinates of points\n",
        "*   UAC \n",
        "*   IIR\n",
        "*   aligned signals\n",
        "*   signals\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gO-SVTrYDvni"
      },
      "outputs": [],
      "source": [
        "df_og = pd.read_csv('LAsignals.csv')\n",
        "# remove index column\n",
        "df_og = df_og.iloc[:,-len(df_og.columns.values)+1:]\n",
        "# tidy the dataset\n",
        "start_index = 6 # index used to select only the signals from df\n",
        "signals = df_og.iloc[:,start_index:].values\n",
        "coordinates = df_og.iloc[:,:3]\n",
        "coordinates = coordinates.values.astype('<f4')\n",
        "UAC = df_og.iloc[:,3:5].values\n",
        "IIR = df_og.iloc[:,5].values.astype('<f2')\n",
        "aligned_signals = pd.read_csv('aligned_LAsignals.csv', header = None)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ja2bbAhxGk8B"
      },
      "source": [
        "# 2) Voronoi Tessellation algorithm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9P4PxKpSiTpj"
      },
      "source": [
        "**Hyperparameters:**\n",
        "\n",
        "* `B`: number of bootstrap iterations\n",
        "* `n`: number of nuclei\n",
        "* `p`: used for dimensionality reduction (e.g. if p=3 we end up with vectors with 3 components)\n",
        "* `K`: number of classes (always equal to 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w58m8Yi3Gg-y",
        "outputId": "fb0f278b-e6fb-467f-cbcf-614965c93d2a"
      },
      "outputs": [],
      "source": [
        "def teseo(n, threshold, B = 500, K = 2):\n",
        "  log = TeseoLogger(os.path.join(os.getcwd(), \"teseo_logs\"), \"log.txt\", encoding = [\"threshold\", \"iteration_time\", \"dimensionality_reduction\", \"average_normalized_entropy\", \"distance_matrix_size\", \"number_of_nucei\", \"num_of_iterations\"])\n",
        "  # random.seed(0)\n",
        "  t0 = time()\n",
        "  classification_matrix = np.zeros((coordinates.shape[0], 1)).astype('<i2')\n",
        "  average_normalized_entropy = np.zeros((B,1))\n",
        "  for b in tqdm(range(B)):\n",
        "    t1 = time()\n",
        "    nuclei_indices = np.array(random.sample(list(np.arange(coordinates.shape[0])), n)) \n",
        "    nuclei_coordinates = np.zeros((n, coordinates.shape[1])) \n",
        "    nuclei_coordinates = coordinates[nuclei_indices, :]\n",
        "    distances = euclidean_distances(coordinates, nuclei_coordinates)\n",
        "    min_index = np.argmin(distances, axis = 1)\n",
        "    log.write(\"distance_matrix_size\" + \" \" + str(getsizeof(distances)/1000000000))\n",
        "    weights = np.zeros(coordinates.shape[0])\n",
        "    idx = np.arange(coordinates.shape[0])\n",
        "    weights[nuclei_indices] = 1\n",
        "    del distances\n",
        "    representative = np.zeros((n, aligned_signals.shape[1]))  \n",
        "    representative = aligned_signals.values[nuclei_indices]\n",
        "    del weights\n",
        "    fd = np.diff(representative)\n",
        "    teta = 5\n",
        "    d = np.sqrt(euclidean_distances(representative, representative)**2 + teta*euclidean_distances(fd, fd)**2)\n",
        "    c = np.sum(d, axis = 1)\n",
        "    log.write(\"threshold\" + \" \" + str(threshold))\n",
        "    tau = np.quantile(c, threshold)\n",
        "    labels = np.zeros_like(c, dtype = int)\n",
        "    labels[c < tau] = 1\n",
        "    labels = labels.reshape(-1,)\n",
        "    idx = np.arange(coordinates.shape[0])\n",
        "    for i in range(n):\n",
        "      if labels[i] == 1:\n",
        "        classification_matrix[idx[min_index == i]] += 1\n",
        "    p1 = classification_matrix / (b+1)\n",
        "    p0 = 1 - p1\n",
        "    v0 = np.zeros((coordinates.shape[0], 1))\n",
        "    v1 = np.zeros((coordinates.shape[0], 1))\n",
        "    v0[p0 != 0] = p0[p0 != 0] * np.log(p0[p0 != 0])\n",
        "    v1[p1 != 0] = p1[p1 != 0] * np.log(p1[p1 != 0])\n",
        "    average_normalized_entropy[b] = - np.sum(( v0 + v1 )) / (np.log(2) * coordinates.shape[0])\n",
        "    del p0, p1, v0, v1, labels, idx\n",
        "    log.write(\"iteration_time\" + \" \" + str(time() - t1))\n",
        "    log.write(\"dimensionality_reduction\" + \" \" + \"None\")\n",
        "    log.write(\"average_normalized_entropy\" + \" \" + str(float(average_normalized_entropy[b])))\n",
        "    log.write(\"number_of_nucei\" + \" \" + str(n))\n",
        "    log.write(\"num_of_iterations\" + \" \" + str(B))\n",
        "  return log , classification_matrix\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "thresholds = [0.01, 0.05, 0.1, 0.2]\n",
        "ns = [50, 100, 200, 300, 1000]\n",
        "for n in ns:\n",
        "    for thr in thresholds:\n",
        "        print(\"n:\", n, \";\", \"thr:\", thr)\n",
        "        log , classification_matrix = teseo(n, thr, B = 500, K = 2)\n",
        "        np.save(log.get_directory() + os.sep + \"classification_matrix\", classification_matrix)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "voronoi.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.8.8 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "vscode": {
      "interpreter": {
        "hash": "0d0d1bce3d99a369e1b3692bad887850a832ed7c7f63d0e0d78616c3419ee9db"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
